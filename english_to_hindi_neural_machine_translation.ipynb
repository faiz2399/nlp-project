{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "english-to-hindi-neural-machine-translation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Import Necesary Libraries"
      ],
      "metadata": {
        "id": "95NyvbAfduv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import layers\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import LSTM, Dense,Input, Embedding\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import string\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-03T11:00:14.28039Z",
          "iopub.execute_input": "2022-01-03T11:00:14.280659Z",
          "iopub.status.idle": "2022-01-03T11:00:14.286624Z",
          "shell.execute_reply.started": "2022-01-03T11:00:14.280628Z",
          "shell.execute_reply": "2022-01-03T11:00:14.285879Z"
        },
        "trusted": true,
        "id": "wOIUVJSyduwB"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Z_hpnNNEiEPK"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sk_OiO_JhrKa",
        "outputId": "8cc7c5cb-5285-4f91-943e-eaac1e9f97aa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('Hindi_English_Truncated_Corpus.csv',encoding='utf-8')\n",
        "data.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-03T11:00:14.708255Z",
          "iopub.execute_input": "2022-01-03T11:00:14.708694Z",
          "iopub.status.idle": "2022-01-03T11:00:15.341744Z",
          "shell.execute_reply.started": "2022-01-03T11:00:14.708662Z",
          "shell.execute_reply": "2022-01-03T11:00:15.340236Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "g6-P8xNjduwC",
        "outputId": "304747e6-a89f-43d4-d163-e9d3fdd73ae2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      source                                   english_sentence  \\\n",
              "0        ted  politicians do not have permission to do what ...   \n",
              "1        ted         I'd like to tell you about one such child,   \n",
              "2  indic2012  This percentage is even greater than the perce...   \n",
              "3        ted  what we really mean is that they're bad at not...   \n",
              "4  indic2012  .The ending portion of these Vedas is called U...   \n",
              "\n",
              "                                      hindi_sentence  \n",
              "0  राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...  \n",
              "1  मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...  \n",
              "2   यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।  \n",
              "3     हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते  \n",
              "4        इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5986e5c8-50aa-467d-aa77-4b0abe6fa95c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>english_sentence</th>\n",
              "      <th>hindi_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ted</td>\n",
              "      <td>politicians do not have permission to do what ...</td>\n",
              "      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ted</td>\n",
              "      <td>I'd like to tell you about one such child,</td>\n",
              "      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>This percentage is even greater than the perce...</td>\n",
              "      <td>यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ted</td>\n",
              "      <td>what we really mean is that they're bad at not...</td>\n",
              "      <td>हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>.The ending portion of these Vedas is called U...</td>\n",
              "      <td>इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5986e5c8-50aa-467d-aa77-4b0abe6fa95c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5986e5c8-50aa-467d-aa77-4b0abe6fa95c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5986e5c8-50aa-467d-aa77-4b0abe6fa95c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# counting sources\n",
        "data['source'].value_counts()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-03T11:00:15.343345Z",
          "iopub.execute_input": "2022-01-03T11:00:15.34361Z",
          "iopub.status.idle": "2022-01-03T11:00:15.363925Z",
          "shell.execute_reply.started": "2022-01-03T11:00:15.343574Z",
          "shell.execute_reply": "2022-01-03T11:00:15.363006Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-_JHwIhduwD",
        "outputId": "edb31f63-949a-49d6-bacf-9a6c6f265fba"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tides        50000\n",
              "ted          39881\n",
              "indic2012    37726\n",
              "Name: source, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sns.countplot(data['source'],data = data)\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-03T11:00:16.098702Z",
          "iopub.execute_input": "2022-01-03T11:00:16.099028Z",
          "iopub.status.idle": "2022-01-03T11:00:16.503248Z",
          "shell.execute_reply.started": "2022-01-03T11:00:16.098987Z",
          "shell.execute_reply": "2022-01-03T11:00:16.502471Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "M-JlIfBOduwD",
        "outputId": "3a192f3c-7aaf-4fe1-d15e-912a9bcf388e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total data: \",data.shape[0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-03T11:00:16.504881Z",
          "iopub.execute_input": "2022-01-03T11:00:16.505328Z",
          "iopub.status.idle": "2022-01-03T11:00:16.513251Z",
          "shell.execute_reply.started": "2022-01-03T11:00:16.50529Z",
          "shell.execute_reply": "2022-01-03T11:00:16.512215Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDUlcOxaduwD",
        "outputId": "19153395-cb52-41a3-becb-d2a6625c9f56"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total data:  127607\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# selcting data with source ted\n",
        "data = data[data.source == 'ted']\n",
        "data.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-03T11:00:17.134082Z",
          "iopub.execute_input": "2022-01-03T11:00:17.134807Z",
          "iopub.status.idle": "2022-01-03T11:00:17.163304Z",
          "shell.execute_reply.started": "2022-01-03T11:00:17.134769Z",
          "shell.execute_reply": "2022-01-03T11:00:17.162602Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrlWPGFiduwE",
        "outputId": "2cf32f5a-aa1e-45d8-a56d-97eb586c73ea"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(39881, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checking null values\n",
        "data.isna().sum()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-03T11:00:17.850774Z",
          "iopub.execute_input": "2022-01-03T11:00:17.851152Z",
          "iopub.status.idle": "2022-01-03T11:00:17.87377Z",
          "shell.execute_reply.started": "2022-01-03T11:00:17.851118Z",
          "shell.execute_reply": "2022-01-03T11:00:17.87245Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CEmFnUFduwE",
        "outputId": "255740fd-0e16-413b-896c-239a3e895728"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "source              0\n",
              "english_sentence    0\n",
              "hindi_sentence      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checking duplicated data\n",
        "isDuplicated = data.duplicated().any()\n",
        "if isDuplicated:\n",
        "    total_duplicates = data.duplicated().sum()\n",
        "    print(\"Total duplicate rows are: \",total_duplicates)\n",
        "    data.drop_duplicates(inplace = True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-03T11:00:18.152477Z",
          "iopub.execute_input": "2022-01-03T11:00:18.152733Z",
          "iopub.status.idle": "2022-01-03T11:00:18.254342Z",
          "shell.execute_reply.started": "2022-01-03T11:00:18.152704Z",
          "shell.execute_reply": "2022-01-03T11:00:18.253589Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBTBmb9WduwF",
        "outputId": "a576039b-90d8-48d4-d549-3b32869ef904"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total duplicate rows are:  1078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## sampling 20000 rows randomly\n",
        "data = data.sample(n = 20000, random_state = 31)\n",
        "data.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-03T11:00:18.946328Z",
          "iopub.execute_input": "2022-01-03T11:00:18.946709Z",
          "iopub.status.idle": "2022-01-03T11:00:18.960666Z",
          "shell.execute_reply.started": "2022-01-03T11:00:18.946677Z",
          "shell.execute_reply": "2022-01-03T11:00:18.959935Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pC1XXHlCduwG",
        "outputId": "a9507e1c-721a-4393-a827-29656f1ddee2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text preprocessing"
      ],
      "metadata": {
        "id": "MPrQaMc5duwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## changing uppercase to lowercase\n",
        "data['english_sentence'] = data['english_sentence'].apply(lambda x: x.lower())\n",
        "data['hindi_sentence']=data['hindi_sentence'].apply(lambda x: x.lower())\n",
        "\n",
        "# Remove quotes\n",
        "data['english_sentence']=data['english_sentence'].apply(lambda x: re.sub(\"'\", '', x))\n",
        "data['hindi_sentence']=data['hindi_sentence'].apply(lambda x: re.sub(\"'\", '', x))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-03T11:00:25.024034Z",
          "iopub.execute_input": "2022-01-03T11:00:25.02464Z",
          "iopub.status.idle": "2022-01-03T11:00:25.111316Z",
          "shell.execute_reply.started": "2022-01-03T11:00:25.024601Z",
          "shell.execute_reply": "2022-01-03T11:00:25.110612Z"
        },
        "trusted": true,
        "id": "LfANOiOeduwG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_exclude = set(string.punctuation) # Set of all special characters\n",
        "print(\"punctuations to exclude:: \",to_exclude)\n",
        "# Remove all the special characters\n",
        "data['english_sentence']=data['english_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in to_exclude))\n",
        "data['hindi_sentence']=data['hindi_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in to_exclude))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-03T11:00:25.851549Z",
          "iopub.execute_input": "2022-01-03T11:00:25.851815Z",
          "iopub.status.idle": "2022-01-03T11:00:26.084273Z",
          "shell.execute_reply.started": "2022-01-03T11:00:25.851784Z",
          "shell.execute_reply": "2022-01-03T11:00:26.083524Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdPp0rNpduwH",
        "outputId": "9a9047e6-bddb-4f7c-a14a-ca1220a9a20b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "punctuations to exclude::  {'-', '{', '~', '%', '.', '^', '>', ':', '!', '<', '[', '}', '`', '|', ')', '+', '*', '$', '/', '#', ']', '=', '\"', '_', '\\\\', '(', '?', '&', ';', \"'\", '@', ','}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from string import digits\n",
        "# Remove all numbers from text\n",
        "remove_digits = str.maketrans('', '', digits)\n",
        "\n",
        "data['english_sentence']=data['english_sentence'].apply(lambda x: x.translate(remove_digits))\n",
        "data['hindi_sentence']=data['hindi_sentence'].apply(lambda x: x.translate(remove_digits))\n",
        "\n",
        "data['hindi_sentence'] = data['hindi_sentence'].apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n",
        "\n",
        "# Remove extra spaces\n",
        "data['english_sentence']=data['english_sentence'].apply(lambda x: x.strip())\n",
        "data['hindi_sentence']=data['hindi_sentence'].apply(lambda x: x.strip())\n",
        "data['english_sentence']=data['english_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
        "data['hindi_sentence']=data['hindi_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-03T11:00:35.362992Z",
          "iopub.execute_input": "2022-01-03T11:00:35.363274Z",
          "iopub.status.idle": "2022-01-03T11:00:35.700307Z",
          "shell.execute_reply.started": "2022-01-03T11:00:35.363242Z",
          "shell.execute_reply": "2022-01-03T11:00:35.699527Z"
        },
        "trusted": true,
        "id": "C7Wb0zi2duwH"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## adding start and end token to the target sentence\n",
        "data['hindi_sentence'] = data['hindi_sentence'].apply(lambda x: \"START_ \" + x + \" _END\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-03T11:00:42.16491Z",
          "iopub.execute_input": "2022-01-03T11:00:42.165191Z",
          "iopub.status.idle": "2022-01-03T11:00:42.181792Z",
          "shell.execute_reply.started": "2022-01-03T11:00:42.165142Z",
          "shell.execute_reply": "2022-01-03T11:00:42.180853Z"
        },
        "trusted": true,
        "id": "gbwjHIDIduwI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## counting length of english and hindi sentence\n",
        "data['english_length'] = data['english_sentence'].apply(lambda x: len(x.split(' ')))\n",
        "data['hindi_length'] = data['hindi_sentence'].apply(lambda x: len(x.split(' ')))\n",
        "\n",
        "data.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-03T11:00:47.083978Z",
          "iopub.execute_input": "2022-01-03T11:00:47.084537Z",
          "iopub.status.idle": "2022-01-03T11:00:47.14273Z",
          "shell.execute_reply.started": "2022-01-03T11:00:47.084498Z",
          "shell.execute_reply": "2022-01-03T11:00:47.142062Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "3kbeSSLHduwI",
        "outputId": "59300d4d-4b08-4aae-9f59-db0818355e88"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       source                                   english_sentence  \\\n",
              "123152    ted             is not about belief but about behavior   \n",
              "31468     ted   than the story were going to tell about it later   \n",
              "102720    ted  and if they need a pair of glasses they are av...   \n",
              "40273     ted                     the feedback here is immediate   \n",
              "17027     ted  a rather astonishing demonstration of the abil...   \n",
              "\n",
              "                                           hindi_sentence  english_length  \\\n",
              "123152  START_ वो विश्वास के बारे में नहीं वरन लेकिन व...               7   \n",
              "31468       START_ उससे जो हम बाद में बताने वाले हैं _END              10   \n",
              "102720  START_ यदि किसी को चश्मे की ज़रूरत है तो उसे श...              17   \n",
              "40273               START_ यहाँ तुरंत नतीजा मिलता है _END               5   \n",
              "17027   START_ यह दिमाग की एक अद्भुत क्षमता का प्रदर्श...              10   \n",
              "\n",
              "        hindi_length  \n",
              "123152            14  \n",
              "31468             10  \n",
              "102720            19  \n",
              "40273              7  \n",
              "17027             11  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f6ecb25e-0480-4610-99df-383768517cbc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>english_sentence</th>\n",
              "      <th>hindi_sentence</th>\n",
              "      <th>english_length</th>\n",
              "      <th>hindi_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>123152</th>\n",
              "      <td>ted</td>\n",
              "      <td>is not about belief but about behavior</td>\n",
              "      <td>START_ वो विश्वास के बारे में नहीं वरन लेकिन व...</td>\n",
              "      <td>7</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31468</th>\n",
              "      <td>ted</td>\n",
              "      <td>than the story were going to tell about it later</td>\n",
              "      <td>START_ उससे जो हम बाद में बताने वाले हैं _END</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102720</th>\n",
              "      <td>ted</td>\n",
              "      <td>and if they need a pair of glasses they are av...</td>\n",
              "      <td>START_ यदि किसी को चश्मे की ज़रूरत है तो उसे श...</td>\n",
              "      <td>17</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40273</th>\n",
              "      <td>ted</td>\n",
              "      <td>the feedback here is immediate</td>\n",
              "      <td>START_ यहाँ तुरंत नतीजा मिलता है _END</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17027</th>\n",
              "      <td>ted</td>\n",
              "      <td>a rather astonishing demonstration of the abil...</td>\n",
              "      <td>START_ यह दिमाग की एक अद्भुत क्षमता का प्रदर्श...</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f6ecb25e-0480-4610-99df-383768517cbc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f6ecb25e-0480-4610-99df-383768517cbc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f6ecb25e-0480-4610-99df-383768517cbc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Maximum length of English Sentence: \", max(data['english_length']))\n",
        "print(\"Maximum length of Hindi Sentence: \",max(data['hindi_length']))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-03T11:00:48.560906Z",
          "iopub.execute_input": "2022-01-03T11:00:48.561201Z",
          "iopub.status.idle": "2022-01-03T11:00:48.572223Z",
          "shell.execute_reply.started": "2022-01-03T11:00:48.561152Z",
          "shell.execute_reply": "2022-01-03T11:00:48.571375Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBys-5kUduwJ",
        "outputId": "677a08a3-1856-48c8-e8ff-c9c615659290"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum length of English Sentence:  21\n",
            "Maximum length of Hindi Sentence:  32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Get English and Hindi Vocabulary\n",
        "all_eng_words=set()\n",
        "for eng in data['english_sentence']:\n",
        "    for word in eng.split():\n",
        "        if word not in all_eng_words:\n",
        "            all_eng_words.add(word)\n",
        "\n",
        "all_hindi_words=set()\n",
        "for hin in data['hindi_sentence']:\n",
        "    for word in hin.split():\n",
        "        if word not in all_hindi_words:\n",
        "            all_hindi_words.add(word)\n",
        "            \n",
        "\n",
        "print(\"toral english words: \",len(all_eng_words))\n",
        "print('total hind words: ',len(all_hindi_words))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-03T11:00:49.807741Z",
          "iopub.execute_input": "2022-01-03T11:00:49.808021Z",
          "iopub.status.idle": "2022-01-03T11:00:49.922114Z",
          "shell.execute_reply.started": "2022-01-03T11:00:49.80799Z",
          "shell.execute_reply": "2022-01-03T11:00:49.921202Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4JzQKpmduwJ",
        "outputId": "95f1d894-a8f4-470e-8ade-ddc679e47a02"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "toral english words:  12483\n",
            "total hind words:  15529\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## using only sentence with length less than 20\n",
        "mask1 = data['english_length'] < 21\n",
        "mask2 = data['hindi_length'] < 21\n",
        "data = data[mask1 & mask2]\n",
        "data.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-03T11:00:51.516274Z",
          "iopub.execute_input": "2022-01-03T11:00:51.516695Z",
          "iopub.status.idle": "2022-01-03T11:00:51.529003Z",
          "shell.execute_reply.started": "2022-01-03T11:00:51.516655Z",
          "shell.execute_reply": "2022-01-03T11:00:51.528122Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpLN_6xjduwJ",
        "outputId": "4150c8e2-767e-4629-9330-6b4f33c7c0cb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19830, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"maximum length of Hindi Sentence \",max(data['hindi_length']))\n",
        "print(\"maximum length of English Sentence \",max(data['english_length']))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-03T11:00:52.589861Z",
          "iopub.execute_input": "2022-01-03T11:00:52.590182Z",
          "iopub.status.idle": "2022-01-03T11:00:52.601117Z",
          "shell.execute_reply.started": "2022-01-03T11:00:52.590137Z",
          "shell.execute_reply": "2022-01-03T11:00:52.599956Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjlN8jgBduwJ",
        "outputId": "d150c21e-4398-4339-a310-47be5bbc9a07"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "maximum length of Hindi Sentence  20\n",
            "maximum length of English Sentence  20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_words = sorted(list(all_eng_words))\n",
        "target_words = sorted(list(all_hindi_words))\n",
        "num_encoder_tokens = len(all_eng_words)\n",
        "num_decoder_tokens = len(all_hindi_words)\n",
        "\n",
        "num_encoder_tokens, num_decoder_tokens"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-03T11:00:54.488285Z",
          "iopub.execute_input": "2022-01-03T11:00:54.490354Z",
          "iopub.status.idle": "2022-01-03T11:00:54.510089Z",
          "shell.execute_reply.started": "2022-01-03T11:00:54.4903Z",
          "shell.execute_reply": "2022-01-03T11:00:54.509416Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcSed5kLduwK",
        "outputId": "97a49733-a17e-452d-c0d3-da2b5dbbd857"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12483, 15529)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_decoder_tokens += 1 #for zero padding\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-03T11:01:01.340882Z",
          "iopub.execute_input": "2022-01-03T11:01:01.341423Z",
          "iopub.status.idle": "2022-01-03T11:01:01.34532Z",
          "shell.execute_reply.started": "2022-01-03T11:01:01.341382Z",
          "shell.execute_reply": "2022-01-03T11:01:01.344232Z"
        },
        "trusted": true,
        "id": "BFrIfbYAduwK"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
        "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])\n",
        "print(\"Token for accelerating is: \",input_token_index['accelerating'])\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-03T11:01:26.46345Z",
          "iopub.execute_input": "2022-01-03T11:01:26.463706Z",
          "iopub.status.idle": "2022-01-03T11:01:26.481718Z",
          "shell.execute_reply.started": "2022-01-03T11:01:26.463677Z",
          "shell.execute_reply": "2022-01-03T11:01:26.480843Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0s6uOy4duwK",
        "outputId": "a83bf009-c823-46a1-adb0-8b105eb207f5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token for accelerating is:  50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())\n",
        "print(\"Character for toker 50 is: \",reverse_input_char_index[50])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-03T11:01:26.815051Z",
          "iopub.execute_input": "2022-01-03T11:01:26.815507Z",
          "iopub.status.idle": "2022-01-03T11:01:26.830545Z",
          "shell.execute_reply.started": "2022-01-03T11:01:26.815474Z",
          "shell.execute_reply": "2022-01-03T11:01:26.829838Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVh_92CJduwK",
        "outputId": "2d8819f5-8325-480b-db8b-90029fdb98cb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Character for toker 50 is:  accelerating\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting data\n",
        "X_, y_ = data['english_sentence'], data['hindi_sentence']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_, y_, test_size = 0.2,random_state=42)\n",
        "print(\"Total number of training data: \",X_train.shape[0])\n",
        "print(\"Toral number of testing data: \",X_test.shape[0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-03T11:01:28.387478Z",
          "iopub.execute_input": "2022-01-03T11:01:28.387738Z",
          "iopub.status.idle": "2022-01-03T11:01:28.403095Z",
          "shell.execute_reply.started": "2022-01-03T11:01:28.387707Z",
          "shell.execute_reply": "2022-01-03T11:01:28.402246Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCfeuuaGduwK",
        "outputId": "737ff84b-1525-453a-c383-0649d5a5f917"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of training data:  15864\n",
            "Toral number of testing data:  3966\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 300\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-03T11:01:28.725311Z",
          "iopub.execute_input": "2022-01-03T11:01:28.725665Z",
          "iopub.status.idle": "2022-01-03T11:02:28.702561Z",
          "shell.execute_reply.started": "2022-01-03T11:01:28.725632Z",
          "shell.execute_reply": "2022-01-03T11:02:28.701851Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5PbzDaEduwK",
        "outputId": "9537443b-30e8-4907-a136-7c29d62d2a5e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, None, 300)    3744900     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 300)    4659000     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 300),        721200      ['embedding[0][0]']              \n",
            "                                 (None, 300),                                                     \n",
            "                                 (None, 300)]                                                     \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 300),  721200      ['embedding_1[0][0]',            \n",
            "                                 (None, 300),                     'lstm[0][1]',                   \n",
            "                                 (None, 300)]                     'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 15530)  4674530     ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 14,520,830\n",
            "Trainable params: 14,520,830\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-03T11:02:28.70419Z",
          "iopub.execute_input": "2022-01-03T11:02:28.704469Z",
          "iopub.status.idle": "2022-01-03T11:02:28.713996Z",
          "shell.execute_reply.started": "2022-01-03T11:02:28.704434Z",
          "shell.execute_reply": "2022-01-03T11:02:28.713224Z"
        },
        "trusted": true,
        "id": "jAEyxb0hduwL"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length_src = 20\n",
        "max_length_tar = 20 \n",
        "\n",
        "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
        "    ''' Generate a batch of data '''\n",
        "    while True:\n",
        "        for j in range(0, len(X), batch_size):\n",
        "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
        "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
        "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
        "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
        "                for t, word in enumerate(input_text.split()):\n",
        "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
        "                for t, word in enumerate(target_text.split()):\n",
        "                    if t<len(target_text.split())-1:\n",
        "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
        "                    if t>0:\n",
        "                        # decoder target sequence (one hot encoded)\n",
        "                        # does not include the START_ token\n",
        "                        # Offset by one timestep\n",
        "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
        "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-03T11:02:28.715125Z",
          "iopub.execute_input": "2022-01-03T11:02:28.71584Z",
          "iopub.status.idle": "2022-01-03T11:02:28.726061Z",
          "shell.execute_reply.started": "2022-01-03T11:02:28.715793Z",
          "shell.execute_reply": "2022-01-03T11:02:28.7253Z"
        },
        "trusted": true,
        "id": "LNB5WDKFduwL"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_samples = len(X_train)\n",
        "val_samples = len(X_test)\n",
        "batch_size = 128\n",
        "epochs = 100"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-03T11:02:28.727983Z",
          "iopub.execute_input": "2022-01-03T11:02:28.728405Z",
          "iopub.status.idle": "2022-01-03T11:02:28.737982Z",
          "shell.execute_reply.started": "2022-01-03T11:02:28.728368Z",
          "shell.execute_reply": "2022-01-03T11:02:28.737305Z"
        },
        "trusted": true,
        "id": "MCRq1osvduwL"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "V-BpQ2r5lWft"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
        "                    steps_per_epoch = train_samples//batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
        "                    validation_steps = val_samples//batch_size)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-03T11:04:23.070067Z",
          "iopub.execute_input": "2022-01-03T11:04:23.07077Z",
          "iopub.status.idle": "2022-01-03T11:13:44.174311Z",
          "shell.execute_reply.started": "2022-01-03T11:04:23.070733Z",
          "shell.execute_reply": "2022-01-03T11:13:44.17236Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JO0pphIzduwL",
        "outputId": "bee3d67f-e888-497a-9b10-89df812bfa5a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "123/123 [==============================] - 43s 239ms/step - loss: 3.0231 - accuracy: 0.1300 - val_loss: 2.9226 - val_accuracy: 0.1383\n",
            "Epoch 2/100\n",
            "123/123 [==============================] - 22s 178ms/step - loss: 2.7794 - accuracy: 0.1494 - val_loss: 2.7901 - val_accuracy: 0.1673\n",
            "Epoch 3/100\n",
            "123/123 [==============================] - 23s 184ms/step - loss: 2.6133 - accuracy: 0.1833 - val_loss: 2.6907 - val_accuracy: 0.1932\n",
            "Epoch 4/100\n",
            "123/123 [==============================] - 22s 175ms/step - loss: 2.4956 - accuracy: 0.2044 - val_loss: 2.6487 - val_accuracy: 0.2051\n",
            "Epoch 5/100\n",
            "123/123 [==============================] - 22s 178ms/step - loss: 2.4044 - accuracy: 0.2210 - val_loss: 2.6039 - val_accuracy: 0.2173\n",
            "Epoch 6/100\n",
            "123/123 [==============================] - 22s 177ms/step - loss: 2.3256 - accuracy: 0.2359 - val_loss: 2.5844 - val_accuracy: 0.2239\n",
            "Epoch 7/100\n",
            "123/123 [==============================] - 22s 183ms/step - loss: 2.2478 - accuracy: 0.2487 - val_loss: 2.5613 - val_accuracy: 0.2310\n",
            "Epoch 8/100\n",
            "123/123 [==============================] - 21s 175ms/step - loss: 2.1760 - accuracy: 0.2611 - val_loss: 2.5395 - val_accuracy: 0.2370\n",
            "Epoch 9/100\n",
            "123/123 [==============================] - 22s 176ms/step - loss: 2.1059 - accuracy: 0.2726 - val_loss: 2.5327 - val_accuracy: 0.2420\n",
            "Epoch 10/100\n",
            "123/123 [==============================] - 22s 176ms/step - loss: 2.0364 - accuracy: 0.2852 - val_loss: 2.5237 - val_accuracy: 0.2463\n",
            "Epoch 11/100\n",
            "123/123 [==============================] - 22s 176ms/step - loss: 1.9726 - accuracy: 0.2965 - val_loss: 2.5281 - val_accuracy: 0.2500\n",
            "Epoch 12/100\n",
            "123/123 [==============================] - 21s 175ms/step - loss: 1.9077 - accuracy: 0.3086 - val_loss: 2.5404 - val_accuracy: 0.2519\n",
            "Epoch 13/100\n",
            "123/123 [==============================] - 22s 176ms/step - loss: 1.8434 - accuracy: 0.3223 - val_loss: 2.5266 - val_accuracy: 0.2512\n",
            "Epoch 14/100\n",
            "123/123 [==============================] - 22s 176ms/step - loss: 1.7806 - accuracy: 0.3343 - val_loss: 2.5380 - val_accuracy: 0.2498\n",
            "Epoch 15/100\n",
            "123/123 [==============================] - 22s 177ms/step - loss: 1.7190 - accuracy: 0.3487 - val_loss: 2.5332 - val_accuracy: 0.2515\n",
            "Epoch 16/100\n",
            "123/123 [==============================] - 22s 176ms/step - loss: 1.6587 - accuracy: 0.3629 - val_loss: 2.5456 - val_accuracy: 0.2485\n",
            "Epoch 17/100\n",
            "123/123 [==============================] - 22s 177ms/step - loss: 1.5981 - accuracy: 0.3779 - val_loss: 2.5628 - val_accuracy: 0.2463\n",
            "Epoch 18/100\n",
            "123/123 [==============================] - 22s 176ms/step - loss: 1.5397 - accuracy: 0.3929 - val_loss: 2.5729 - val_accuracy: 0.2452\n",
            "Epoch 19/100\n",
            "123/123 [==============================] - 22s 175ms/step - loss: 1.4812 - accuracy: 0.4097 - val_loss: 2.5872 - val_accuracy: 0.2465\n",
            "Epoch 20/100\n",
            "123/123 [==============================] - 22s 176ms/step - loss: 1.4239 - accuracy: 0.4256 - val_loss: 2.6067 - val_accuracy: 0.2449\n",
            "Epoch 21/100\n",
            "123/123 [==============================] - 22s 175ms/step - loss: 1.3670 - accuracy: 0.4433 - val_loss: 2.6248 - val_accuracy: 0.2441\n",
            "Epoch 22/100\n",
            "123/123 [==============================] - 22s 175ms/step - loss: 1.3116 - accuracy: 0.4609 - val_loss: 2.6478 - val_accuracy: 0.2437\n",
            "Epoch 23/100\n",
            "123/123 [==============================] - 22s 176ms/step - loss: 1.2591 - accuracy: 0.4801 - val_loss: 2.6688 - val_accuracy: 0.2425\n",
            "Epoch 24/100\n",
            "123/123 [==============================] - 22s 177ms/step - loss: 1.2038 - accuracy: 0.4987 - val_loss: 2.7027 - val_accuracy: 0.2424\n",
            "Epoch 25/100\n",
            "123/123 [==============================] - 22s 175ms/step - loss: 1.1520 - accuracy: 0.5189 - val_loss: 2.7157 - val_accuracy: 0.2395\n",
            "Epoch 26/100\n",
            "123/123 [==============================] - 22s 176ms/step - loss: 1.0998 - accuracy: 0.5389 - val_loss: 2.7318 - val_accuracy: 0.2377\n",
            "Epoch 27/100\n",
            "123/123 [==============================] - 22s 175ms/step - loss: 1.0498 - accuracy: 0.5591 - val_loss: 2.7510 - val_accuracy: 0.2374\n",
            "Epoch 28/100\n",
            "123/123 [==============================] - 22s 178ms/step - loss: 1.0010 - accuracy: 0.5799 - val_loss: 2.7779 - val_accuracy: 0.2352\n",
            "Epoch 29/100\n",
            "123/123 [==============================] - 22s 178ms/step - loss: 0.9532 - accuracy: 0.5994 - val_loss: 2.8064 - val_accuracy: 0.2367\n",
            "Epoch 30/100\n",
            "123/123 [==============================] - 22s 179ms/step - loss: 0.9068 - accuracy: 0.6206 - val_loss: 2.8258 - val_accuracy: 0.2331\n",
            "Epoch 31/100\n",
            "123/123 [==============================] - 22s 178ms/step - loss: 0.8607 - accuracy: 0.6417 - val_loss: 2.8549 - val_accuracy: 0.2329\n",
            "Epoch 32/100\n",
            "123/123 [==============================] - 22s 180ms/step - loss: 0.8160 - accuracy: 0.6616 - val_loss: 2.8830 - val_accuracy: 0.2339\n",
            "Epoch 33/100\n",
            "123/123 [==============================] - 22s 177ms/step - loss: 0.7727 - accuracy: 0.6822 - val_loss: 2.9078 - val_accuracy: 0.2309\n",
            "Epoch 34/100\n",
            "123/123 [==============================] - 22s 178ms/step - loss: 0.7305 - accuracy: 0.7019 - val_loss: 2.9410 - val_accuracy: 0.2326\n",
            "Epoch 35/100\n",
            "123/123 [==============================] - 22s 178ms/step - loss: 0.6914 - accuracy: 0.7203 - val_loss: 2.9587 - val_accuracy: 0.2294\n",
            "Epoch 36/100\n",
            "123/123 [==============================] - 22s 179ms/step - loss: 0.6529 - accuracy: 0.7390 - val_loss: 2.9800 - val_accuracy: 0.2249\n",
            "Epoch 37/100\n",
            "123/123 [==============================] - 22s 179ms/step - loss: 0.6162 - accuracy: 0.7570 - val_loss: 3.0060 - val_accuracy: 0.2265\n",
            "Epoch 38/100\n",
            "123/123 [==============================] - 22s 181ms/step - loss: 0.5803 - accuracy: 0.7722 - val_loss: 3.0281 - val_accuracy: 0.2249\n",
            "Epoch 39/100\n",
            "123/123 [==============================] - 22s 182ms/step - loss: 0.5462 - accuracy: 0.7913 - val_loss: 3.0510 - val_accuracy: 0.2219\n",
            "Epoch 40/100\n",
            "123/123 [==============================] - 23s 184ms/step - loss: 0.5127 - accuracy: 0.8059 - val_loss: 3.0763 - val_accuracy: 0.2235\n",
            "Epoch 41/100\n",
            "123/123 [==============================] - 22s 183ms/step - loss: 0.4826 - accuracy: 0.8212 - val_loss: 3.0887 - val_accuracy: 0.2240\n",
            "Epoch 42/100\n",
            "123/123 [==============================] - 22s 183ms/step - loss: 0.4535 - accuracy: 0.8354 - val_loss: 3.1136 - val_accuracy: 0.2216\n",
            "Epoch 43/100\n",
            "123/123 [==============================] - 23s 184ms/step - loss: 0.4250 - accuracy: 0.8485 - val_loss: 3.1395 - val_accuracy: 0.2223\n",
            "Epoch 44/100\n",
            "123/123 [==============================] - 23s 184ms/step - loss: 0.3966 - accuracy: 0.8623 - val_loss: 3.1570 - val_accuracy: 0.2187\n",
            "Epoch 45/100\n",
            "123/123 [==============================] - 22s 182ms/step - loss: 0.3709 - accuracy: 0.8755 - val_loss: 3.1869 - val_accuracy: 0.2204\n",
            "Epoch 46/100\n",
            "123/123 [==============================] - 22s 182ms/step - loss: 0.3471 - accuracy: 0.8870 - val_loss: 3.2182 - val_accuracy: 0.2207\n",
            "Epoch 47/100\n",
            "123/123 [==============================] - 23s 184ms/step - loss: 0.3222 - accuracy: 0.8981 - val_loss: 3.2301 - val_accuracy: 0.2197\n",
            "Epoch 48/100\n",
            "123/123 [==============================] - 22s 183ms/step - loss: 0.2999 - accuracy: 0.9083 - val_loss: 3.2500 - val_accuracy: 0.2201\n",
            "Epoch 49/100\n",
            "123/123 [==============================] - 22s 183ms/step - loss: 0.2785 - accuracy: 0.9189 - val_loss: 3.2732 - val_accuracy: 0.2187\n",
            "Epoch 50/100\n",
            "123/123 [==============================] - 22s 183ms/step - loss: 0.2598 - accuracy: 0.9263 - val_loss: 3.3023 - val_accuracy: 0.2177\n",
            "Epoch 51/100\n",
            "123/123 [==============================] - 22s 182ms/step - loss: 0.2401 - accuracy: 0.9347 - val_loss: 3.3184 - val_accuracy: 0.2175\n",
            "Epoch 52/100\n",
            "123/123 [==============================] - 22s 182ms/step - loss: 0.2237 - accuracy: 0.9418 - val_loss: 3.3573 - val_accuracy: 0.2164\n",
            "Epoch 53/100\n",
            "123/123 [==============================] - 22s 182ms/step - loss: 0.2072 - accuracy: 0.9485 - val_loss: 3.3752 - val_accuracy: 0.2172\n",
            "Epoch 54/100\n",
            "123/123 [==============================] - 23s 183ms/step - loss: 0.1917 - accuracy: 0.9549 - val_loss: 3.3979 - val_accuracy: 0.2167\n",
            "Epoch 55/100\n",
            "123/123 [==============================] - 23s 183ms/step - loss: 0.1769 - accuracy: 0.9602 - val_loss: 3.4099 - val_accuracy: 0.2143\n",
            "Epoch 56/100\n",
            "123/123 [==============================] - 22s 182ms/step - loss: 0.1632 - accuracy: 0.9655 - val_loss: 3.4313 - val_accuracy: 0.2118\n",
            "Epoch 57/100\n",
            "123/123 [==============================] - 22s 182ms/step - loss: 0.1515 - accuracy: 0.9692 - val_loss: 3.4595 - val_accuracy: 0.2148\n",
            "Epoch 58/100\n",
            "123/123 [==============================] - 22s 183ms/step - loss: 0.1385 - accuracy: 0.9738 - val_loss: 3.4796 - val_accuracy: 0.2112\n",
            "Epoch 59/100\n",
            "123/123 [==============================] - 22s 183ms/step - loss: 0.1273 - accuracy: 0.9775 - val_loss: 3.4939 - val_accuracy: 0.2120\n",
            "Epoch 60/100\n",
            "123/123 [==============================] - 22s 183ms/step - loss: 0.1177 - accuracy: 0.9807 - val_loss: 3.5294 - val_accuracy: 0.2124\n",
            "Epoch 61/100\n",
            "123/123 [==============================] - 22s 183ms/step - loss: 0.1080 - accuracy: 0.9832 - val_loss: 3.5358 - val_accuracy: 0.2107\n",
            "Epoch 62/100\n",
            "123/123 [==============================] - 22s 183ms/step - loss: 0.0995 - accuracy: 0.9851 - val_loss: 3.5665 - val_accuracy: 0.2113\n",
            "Epoch 63/100\n",
            "123/123 [==============================] - 22s 182ms/step - loss: 0.0919 - accuracy: 0.9873 - val_loss: 3.5882 - val_accuracy: 0.2092\n",
            "Epoch 64/100\n",
            "123/123 [==============================] - 23s 183ms/step - loss: 0.0849 - accuracy: 0.9886 - val_loss: 3.6003 - val_accuracy: 0.2110\n",
            "Epoch 65/100\n",
            "123/123 [==============================] - 22s 182ms/step - loss: 0.0785 - accuracy: 0.9897 - val_loss: 3.6234 - val_accuracy: 0.2066\n",
            "Epoch 66/100\n",
            "123/123 [==============================] - 23s 183ms/step - loss: 0.0714 - accuracy: 0.9911 - val_loss: 3.6425 - val_accuracy: 0.2104\n",
            "Epoch 67/100\n",
            "123/123 [==============================] - 23s 186ms/step - loss: 0.0654 - accuracy: 0.9922 - val_loss: 3.6627 - val_accuracy: 0.2112\n",
            "Epoch 68/100\n",
            "123/123 [==============================] - 23s 186ms/step - loss: 0.0609 - accuracy: 0.9931 - val_loss: 3.6804 - val_accuracy: 0.2085\n",
            "Epoch 69/100\n",
            "123/123 [==============================] - 23s 185ms/step - loss: 0.0559 - accuracy: 0.9939 - val_loss: 3.6967 - val_accuracy: 0.2093\n",
            "Epoch 70/100\n",
            "123/123 [==============================] - 23s 187ms/step - loss: 0.0517 - accuracy: 0.9945 - val_loss: 3.7249 - val_accuracy: 0.2118\n",
            "Epoch 71/100\n",
            "123/123 [==============================] - 23s 186ms/step - loss: 0.0480 - accuracy: 0.9950 - val_loss: 3.7273 - val_accuracy: 0.2121\n",
            "Epoch 72/100\n",
            "123/123 [==============================] - 23s 187ms/step - loss: 0.0438 - accuracy: 0.9956 - val_loss: 3.7591 - val_accuracy: 0.2132\n",
            "Epoch 73/100\n",
            "123/123 [==============================] - 23s 185ms/step - loss: 0.0402 - accuracy: 0.9959 - val_loss: 3.7666 - val_accuracy: 0.2102\n",
            "Epoch 74/100\n",
            "123/123 [==============================] - 23s 186ms/step - loss: 0.0376 - accuracy: 0.9962 - val_loss: 3.7862 - val_accuracy: 0.2131\n",
            "Epoch 75/100\n",
            "123/123 [==============================] - 23s 185ms/step - loss: 0.0348 - accuracy: 0.9962 - val_loss: 3.8032 - val_accuracy: 0.2119\n",
            "Epoch 76/100\n",
            "123/123 [==============================] - 23s 186ms/step - loss: 0.0328 - accuracy: 0.9964 - val_loss: 3.8088 - val_accuracy: 0.2113\n",
            "Epoch 77/100\n",
            "123/123 [==============================] - 23s 185ms/step - loss: 0.0302 - accuracy: 0.9970 - val_loss: 3.8308 - val_accuracy: 0.2122\n",
            "Epoch 78/100\n",
            "123/123 [==============================] - 23s 186ms/step - loss: 0.0286 - accuracy: 0.9967 - val_loss: 3.8449 - val_accuracy: 0.2118\n",
            "Epoch 79/100\n",
            "123/123 [==============================] - 23s 185ms/step - loss: 0.0272 - accuracy: 0.9967 - val_loss: 3.8510 - val_accuracy: 0.2098\n",
            "Epoch 80/100\n",
            "123/123 [==============================] - 23s 186ms/step - loss: 0.0249 - accuracy: 0.9972 - val_loss: 3.8720 - val_accuracy: 0.2119\n",
            "Epoch 81/100\n",
            "123/123 [==============================] - 23s 185ms/step - loss: 0.0234 - accuracy: 0.9972 - val_loss: 3.8906 - val_accuracy: 0.2105\n",
            "Epoch 82/100\n",
            "123/123 [==============================] - 23s 187ms/step - loss: 0.0222 - accuracy: 0.9972 - val_loss: 3.9054 - val_accuracy: 0.2114\n",
            "Epoch 83/100\n",
            "123/123 [==============================] - 23s 185ms/step - loss: 0.0209 - accuracy: 0.9972 - val_loss: 3.9048 - val_accuracy: 0.2077\n",
            "Epoch 84/100\n",
            "123/123 [==============================] - 23s 187ms/step - loss: 0.0199 - accuracy: 0.9973 - val_loss: 3.9427 - val_accuracy: 0.2124\n",
            "Epoch 85/100\n",
            "123/123 [==============================] - 23s 187ms/step - loss: 0.0186 - accuracy: 0.9976 - val_loss: 3.9294 - val_accuracy: 0.2121\n",
            "Epoch 86/100\n",
            "123/123 [==============================] - 23s 186ms/step - loss: 0.0176 - accuracy: 0.9975 - val_loss: 3.9625 - val_accuracy: 0.2101\n",
            "Epoch 87/100\n",
            "123/123 [==============================] - 23s 186ms/step - loss: 0.0173 - accuracy: 0.9973 - val_loss: 3.9673 - val_accuracy: 0.2111\n",
            "Epoch 88/100\n",
            "123/123 [==============================] - 23s 187ms/step - loss: 0.0164 - accuracy: 0.9975 - val_loss: 3.9846 - val_accuracy: 0.2109\n",
            "Epoch 89/100\n",
            "123/123 [==============================] - 23s 185ms/step - loss: 0.0156 - accuracy: 0.9975 - val_loss: 4.0071 - val_accuracy: 0.2106\n",
            "Epoch 90/100\n",
            "123/123 [==============================] - 23s 185ms/step - loss: 0.0152 - accuracy: 0.9975 - val_loss: 4.0058 - val_accuracy: 0.2115\n",
            "Epoch 91/100\n",
            "123/123 [==============================] - 23s 185ms/step - loss: 0.0148 - accuracy: 0.9975 - val_loss: 4.0286 - val_accuracy: 0.2091\n",
            "Epoch 92/100\n",
            "123/123 [==============================] - 23s 187ms/step - loss: 0.0131 - accuracy: 0.9981 - val_loss: 4.0375 - val_accuracy: 0.2105\n",
            "Epoch 93/100\n",
            "123/123 [==============================] - 23s 186ms/step - loss: 0.0126 - accuracy: 0.9980 - val_loss: 4.0629 - val_accuracy: 0.2098\n",
            "Epoch 94/100\n",
            "123/123 [==============================] - 23s 186ms/step - loss: 0.0126 - accuracy: 0.9978 - val_loss: 4.0676 - val_accuracy: 0.2093\n",
            "Epoch 95/100\n",
            "123/123 [==============================] - 23s 186ms/step - loss: 0.0122 - accuracy: 0.9977 - val_loss: 4.0766 - val_accuracy: 0.2088\n",
            "Epoch 96/100\n",
            "123/123 [==============================] - 23s 187ms/step - loss: 0.0117 - accuracy: 0.9978 - val_loss: 4.0844 - val_accuracy: 0.2088\n",
            "Epoch 97/100\n",
            "123/123 [==============================] - 23s 186ms/step - loss: 0.0111 - accuracy: 0.9979 - val_loss: 4.0995 - val_accuracy: 0.2089\n",
            "Epoch 98/100\n",
            "123/123 [==============================] - 23s 186ms/step - loss: 0.0111 - accuracy: 0.9978 - val_loss: 4.1211 - val_accuracy: 0.2066\n",
            "Epoch 99/100\n",
            "123/123 [==============================] - 23s 185ms/step - loss: 0.0103 - accuracy: 0.9980 - val_loss: 4.1437 - val_accuracy: 0.2098\n",
            "Epoch 100/100\n",
            "123/123 [==============================] - 23s 188ms/step - loss: 0.0100 - accuracy: 0.9980 - val_loss: 4.1329 - val_accuracy: 0.2092\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f532e38bbd0>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the input sequence to get the \"thought vectors\"\n",
        "encoder_model = tf.keras.Model(encoder_inputs, encoder_states)\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
        "\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = tf.keras.Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs2] + decoder_states2)\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0] = target_token_index['START_']\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += ' '+sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '_END' or\n",
        "           len(decoded_sentence) > 50):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-03T11:03:29.963885Z",
          "iopub.execute_input": "2022-01-03T11:03:29.964155Z",
          "iopub.status.idle": "2022-01-03T11:03:31.297253Z",
          "shell.execute_reply.started": "2022-01-03T11:03:29.964124Z",
          "shell.execute_reply": "2022-01-03T11:03:31.296502Z"
        },
        "trusted": true,
        "id": "TaCwP6n0duwM"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_gen = generate_batch(['politicians are good'], [y_train[0]], batch_size = 1)\n",
        "k = -1"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-03T11:03:31.299104Z",
          "iopub.execute_input": "2022-01-03T11:03:31.299362Z",
          "iopub.status.idle": "2022-01-03T11:03:31.304444Z",
          "shell.execute_reply.started": "2022-01-03T11:03:31.299328Z",
          "shell.execute_reply": "2022-01-03T11:03:31.302602Z"
        },
        "trusted": true,
        "id": "tLHI7UZiduwM"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gayL8gRKtz17"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "(input_seq, actual_output), _ = next(train_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "#print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
        "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-03T11:13:53.189253Z",
          "iopub.execute_input": "2022-01-03T11:13:53.189521Z",
          "iopub.status.idle": "2022-01-03T11:13:53.726422Z",
          "shell.execute_reply.started": "2022-01-03T11:13:53.189492Z",
          "shell.execute_reply": "2022-01-03T11:13:53.725627Z"
        },
        "trusted": true,
        "id": "4e0VYbL2duwM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fe3bbd4-4583-40e1-84a6-e1ec4d1f741c"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Hindi Translation:  बहुत ही चीज़ें हैं \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k = k + 1\n",
        "(input_seq, actual_output), _ = next(train_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', X_train[k:k+1].values[0])\n",
        "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
        "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-03T11:14:12.48096Z",
          "iopub.execute_input": "2022-01-03T11:14:12.48124Z",
          "iopub.status.idle": "2022-01-03T11:14:13.025671Z",
          "shell.execute_reply.started": "2022-01-03T11:14:12.481207Z",
          "shell.execute_reply": "2022-01-03T11:14:13.024377Z"
        },
        "trusted": true,
        "id": "_iC2JB2GduwM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1d5b898-e2de-461e-ec65-4d6f660c11c8"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input English sentence: which occurs in nature\n",
            "Actual Hindi Translation:  जो प्रकृति में होता है \n",
            "Predicted Hindi Translation:  बहुत ही चीज़ें हैं \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k = k + 1\n",
        "(input_seq, actual_output), _ = next(train_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', X_train[k:k+1].values[0])\n",
        "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
        "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-03T11:03:23.546914Z",
          "iopub.status.idle": "2022-01-03T11:03:23.547867Z",
          "shell.execute_reply.started": "2022-01-03T11:03:23.547215Z",
          "shell.execute_reply": "2022-01-03T11:03:23.547279Z"
        },
        "trusted": true,
        "id": "zevNB5uSduwM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9c8f2da-0fe2-4df2-ed79-4de9011f5d86"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input English sentence: are actually going to matter in the long run\n",
            "Actual Hindi Translation:  लंबे समय में हमारे लिए मायने रखते है \n",
            "Predicted Hindi Translation:  प्रकृति और जैसा \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k = k + 1\n",
        "(input_seq, actual_output), _ = next(train_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', X_train[k:k+1].values[0])\n",
        "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
        "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
      ],
      "metadata": {
        "id": "Lxat9pYtduwM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8949887e-0bb2-4f88-a5d8-4950ff93b22f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input English sentence: i mean really though\n",
            "Actual Hindi Translation:  मेरा मतलब सच में कठिन \n",
            "Predicted Hindi Translation:  प्रकृति और जैसा \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k = k + 1\n",
        "(input_seq, actual_output), _ = next(train_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', X_train[k:k+1].values[0])\n",
        "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
        "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-03T11:04:05.896458Z",
          "iopub.execute_input": "2022-01-03T11:04:05.896963Z",
          "iopub.status.idle": "2022-01-03T11:04:06.172343Z",
          "shell.execute_reply.started": "2022-01-03T11:04:05.896924Z",
          "shell.execute_reply": "2022-01-03T11:04:06.171595Z"
        },
        "trusted": true,
        "id": "iPq2PGC3duwM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0ec790b-79cc-4dc4-8324-898bbdfbee3f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input English sentence: and youre aware of how many people are around you\n",
            "Actual Hindi Translation:  और आपको अंदाज़ा है कि कितने लोग आपके आसपास है \n",
            "Predicted Hindi Translation:  प्रकृति और जैसा \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k = k + 1\n",
        "(input_seq, actual_output), _ = next(train_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', X_train[k:k+1].values[0])\n",
        "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
        "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-03T11:04:11.217267Z",
          "iopub.execute_input": "2022-01-03T11:04:11.218037Z",
          "iopub.status.idle": "2022-01-03T11:04:11.651166Z",
          "shell.execute_reply.started": "2022-01-03T11:04:11.217989Z",
          "shell.execute_reply": "2022-01-03T11:04:11.649101Z"
        },
        "trusted": true,
        "id": "Bpl7_sedduwM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd8154f0-e94a-4d09-e2fd-45d31e6e1a3f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input English sentence: and so i get angry and i get pissed\n",
            "Actual Hindi Translation:  क्यों के ये बात पे मुझे बहोत ही अधिक ग़ुस्सा आता है \n",
            "Predicted Hindi Translation:  प्रकृति और जैसा \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xV0Wo5iSduwM"
      },
      "execution_count": 37,
      "outputs": []
    }
  ]
}